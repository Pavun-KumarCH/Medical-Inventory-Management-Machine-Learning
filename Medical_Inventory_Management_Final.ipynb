{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavun-KumarCH/Medical-Inventory-Management-Machine-Learning/blob/main/Medical_Inventory_Management_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<h1><center><strong><font size=\"6\">Medical Inventory Management Project<font><strong></center></h1>"
      ],
      "metadata": {
        "id": "6Nrnl8WzjTBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CRISP - ML(Q)**\n",
        "\n",
        "**CRISP-ML(Q) process model describes six phases:**\n",
        "\n",
        "- Business and Data Understanding\n",
        "- Data Preparation (Data Engineering)\n",
        "- Model Building (Machine Learning)\n",
        "- Model Evaluation and Tunning\n",
        "- Deployment\n",
        "- Monitoring and Maintenance\n",
        "\n",
        "---\n",
        "\n",
        "## **Problem Statements**:\n",
        "Bounce rate is increasing significantly leading to patient dissatisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Business Objective** :\n",
        "Minimize Bounce Rate.\n",
        "\n",
        "### **Business Constraints** :\n",
        "Minimize Inventory Cost.\n",
        "\n",
        "---\n",
        "          \n",
        "## **Success Criteria** : -\n",
        "\n",
        "**Business Success Criteria** : Reduce bounce rate by at least 30%\n",
        "\n",
        "**Machine Learning Success Criteria** : Achieve an Accuracy of at least 90%\n",
        "\n",
        "**Economic Success Criteria** : Increase revenue by at least 20 lacs INR by reducing bounce rate.\n",
        "\n",
        "---\n",
        "\n",
        "### **Data Collection** :\n",
        "                  \n",
        "Data Was Provided client which One of the Leading Pharma Company in india.\n"
      ],
      "metadata": {
        "id": "gooETpEXvm_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Description** :\n",
        "The dataset consists of 14218 entries with the following columns:\n",
        "\n",
        "**VARIABLE NAME - DESCRIPTION**\n",
        "\n",
        "---\n",
        "1. **Typeofsales** :\t*Type of sale of the drug. Either the drug is sold or returned.*\n",
        "\n",
        "2. **Patient_ID** : \t*ID of a patient*\n",
        "\n",
        "3. **Specialisation** :\t*Name of Specialisation (eg. Cardiology)*\n",
        "\n",
        "4. **Dept** :\t        *Pharmacy, the formulation is related with.*\n",
        "\n",
        "5. **Dateofbill** :  \t*Date of purchase of medicine*\n",
        "\n",
        "6. **Quantity** :\t    *Quantity of the drug*\n",
        "\n",
        "7. **ReturnQuantity** :\t*Quantity of drug returned by patient to the pharmacy*\n",
        "\n",
        "8. **Final_Cost** :\t    *Final Cost of the drug (Quantity included)*\n",
        "\n",
        "9. **Final_Sales** :\t*Final sales of drug*\n",
        "\n",
        "10. **RtnMRP** :\t       * MRP of returned drug (Quantity included)*\n",
        "\n",
        "11. **Formulation** :\t*Type of formulation*\n",
        "\n",
        "12. **DrugName** :\t    *Generic name of the drug*\n",
        "\n",
        "13. **SubCat** :\t        *Subcategory (Type) to the category of drugs*\n",
        "\n",
        "14. **SubCat1** :     \t*Subcategory (condition) to the category of drugs*\n"
      ],
      "metadata": {
        "id": "qrtm-yiPvzcx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPf0xphmu8mo"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import io\n",
        "import pylab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "from kneed import KneeLocator\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tslearn\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "from tslearn.metrics import dtw\n",
        "\n",
        "import itertools\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX"
      ],
      "metadata": {
        "id": "mTRl-ztmw4zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n"
      ],
      "metadata": {
        "id": "5Zq9aXSQtM1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress Warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "t2IfgciGN5Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load The Data"
      ],
      "metadata": {
        "id": "v-w_IX_uNn0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# filename = next(iter(uploaded))\n",
        "# filename"
      ],
      "metadata": {
        "id": "TpFSsNQNxDMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# medical_inv = pd.read_excel(io.BytesIO(uploaded[filename]))\n"
      ],
      "metadata": {
        "id": "13ZlU0DRSCEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv = pd.read_excel('/Users/pavankumar/Projects/Medical Inventory Management/Datasets/Medical Inventory Optimaization Dataset.xlsx')\n"
      ],
      "metadata": {
        "id": "COcBSlBWMBon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrive the Data Info"
      ],
      "metadata": {
        "id": "mDMVJBTlNrl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv.info()"
      ],
      "metadata": {
        "id": "Bsuck1rawYDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv"
      ],
      "metadata": {
        "id": "OjZUaTwtuh48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Financial Metric's analysis**\n",
        "\n",
        "Based on the columns 'Quantity', 'Final_Cost', 'Final_Sales', and 'RtnMRP', we can calculate various metrics that provide insights into sales data. Here are some additional calculations we perform:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Total Revenue:\n",
        "    This is the same as Final_Sales.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Total Cost:\n",
        "    This is the same as Final_Cost.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Total Profit:\n",
        "    Calculated as Final_Sales - Final_Cost.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Profit Margin:\n",
        "\n",
        "    Calculated as (Final_Sales - Final_Cost) / Final_Sales. This represents the percentage of revenue that turns into profit.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Return on Investment (ROI):\n",
        "\n",
        "    Calculated as (Final_Sales - Final_Cost) / Final_Cost. This measures the profitability of the investment.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Average Selling Price (ASP):\n",
        "\n",
        "    Calculated as Final_Sales / Quantity. This represents the average price at which each unit is sold.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Average Cost Price (ACP):\n",
        "\n",
        "    Calculated as Final_Cost / Quantity. This represents the average cost of each unit.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Markup:\n",
        "\n",
        "    Calculated as (Final_Sales - Final_Cost) / Final_Cost. This represents the percentage increase over the cost price.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Return Margin:\n",
        "\n",
        "    Calculated as (RtnMRP - Final_Cost) / RtnMRP. This indicates the margin when considering the maximum retail price (MRP) for returns.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Revenue per Quantity:\n",
        "\n",
        "    Calculated as Final_Sales / Quantity. This is similar to ASP but ensures clarity.\n"
      ],
      "metadata": {
        "id": "3mDiO82yHEFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store all related Sales Metrics\n",
        "sales_df = pd.DataFrame(columns = ['Profit'])\n",
        "\n",
        "# Calculate Total Profit\n",
        "sales_df['Profit'] = pd.DataFrame(medical_inv['Final_Sales'] - medical_inv['Final_Cost'])\n",
        "\n",
        "# Calculate Profit Margin\n",
        "sales_df['Profit Margin'] = sales_df['Profit'] / medical_inv['Final_Sales']\n",
        "\n",
        "# Calculate Return on Investment(ROI)\n",
        "sales_df['ROI'] = (medical_inv['Final_Sales'] - medical_inv['Final_Cost'])/ medical_inv['Final_Cost']\n",
        "\n",
        "# Calculate Average Selling Price(ASP)\n",
        "sales_df['ASP'] = medical_inv['Final_Sales']/ medical_inv['Quantity']\n",
        "\n",
        "# Calculate Avreage Cost Price(ACP)\n",
        "sales_df['ACP'] = medical_inv['Final_Cost']/ medical_inv['Quantity']\n",
        "\n",
        "# Calculate Profit per Unit\n",
        "sales_df['Profit per Unit'] = sales_df['Profit'] / medical_inv['Quantity']\n",
        "\n",
        "# Calculate Markup\n",
        "sales_df['Mark up'] = sales_df['Profit'] / medical_inv['Final_Cost']\n",
        "\n",
        "# Calculate Return Mark up\n",
        "sales_df['Return Margin'] = (medical_inv['RtnMRP'] - medical_inv['Final_Cost'])/  medical_inv['RtnMRP']\n",
        "\n",
        "\n",
        "print(f\"The Total Profit sales: {sales_df['Profit'].sum()}\\n\")\n",
        "\n",
        "round(sales_df.describe())"
      ],
      "metadata": {
        "id": "NmxwKIdhH132"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.head()"
      ],
      "metadata": {
        "id": "J_nyROUgHCnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "ypqtGqZClQpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicates Handling\n"
      ],
      "metadata": {
        "id": "xZ4IxyqNRYq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = medical_inv.duplicated()\n",
        "sum(duplicates)"
      ],
      "metadata": {
        "id": "K5dbFP3PRck0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv.drop_duplicates(inplace = True)\n",
        "duplicates = medical_inv.duplicated()\n",
        "sum(duplicates)"
      ],
      "metadata": {
        "id": "BQgb1JvFSYax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values"
      ],
      "metadata": {
        "id": "iB2v30ouNuvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv.isna().sum()\n"
      ],
      "metadata": {
        "id": "VDR9FNkWzWUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Imputation**"
      ],
      "metadata": {
        "id": "XZLiSQ9qO8jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index before applying group-wise mode\n",
        "medical_inv.reset_index(drop = True, inplace = True)"
      ],
      "metadata": {
        "id": "yYvw55XXQn4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values in Formulation column based on the mode of the group\n",
        "group_cols = ['Typeofsales','Specialisation','Dept']\n",
        "\n",
        "for col in ['Formulation', 'DrugName', 'SubCat', 'SubCat1']:\n",
        "    medical_inv[col] = medical_inv.groupby(group_cols)[col].transform(lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x)\n",
        "\n",
        "medical_inv.isna().sum()"
      ],
      "metadata": {
        "id": "qs2PF7CdQ23L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We still have few missing values\n",
        "medical_inv.dropna(inplace = True)\n",
        "medical_inv.reset_index(drop = True, inplace = True)\n",
        "medical_inv.isna().sum()"
      ],
      "metadata": {
        "id": "9LGlxBfaR6EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Manupulation"
      ],
      "metadata": {
        "id": "OJQjGj40S3vY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Date Manipulation\n",
        "medical_inv['Dateofbill'] = pd.to_datetime(medical_inv['Dateofbill'])\n",
        "\n",
        "# Sort the datadet based on date column in ascending order\n",
        "medical_inv = medical_inv.sort_values(by = 'Dateofbill', ascending = True)"
      ],
      "metadata": {
        "id": "RdhDIPUkS_Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Date Range\n",
        "start_date = medical_inv['Dateofbill'].min()\n",
        "end_date = medical_inv['Dateofbill'].max()\n",
        "\n",
        "print(f'Date Range: [{start_date}, {end_date}]')"
      ],
      "metadata": {
        "id": "0qgQ8VfwC6BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Converstion of Date to Months and Weeks\n",
        "# Converting date format to month\n",
        "medical_inv['Months'] = medical_inv['Dateofbill'].dt.strftime(\"%b\")\n",
        "\n",
        "# Converting date format to Week\n",
        "medical_inv['Week'] = medical_inv['Dateofbill'].dt.isocalendar().week\n",
        "\n",
        "# Here in isocalendar a week starts from 1st thrusday so same days in jan might show as week 52 so we are filtering it\n",
        "medical_inv.loc[(medical_inv['Week'] == 52) & (medical_inv['Dateofbill'].dt.month == 1), 'Week'] = 1\n",
        "\n",
        "medical_inv.reset_index(drop = True, inplace = True)"
      ],
      "metadata": {
        "id": "061sJsvdYW59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(medical_inv.head(5))"
      ],
      "metadata": {
        "id": "LsKLrvSmuH3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(medical_inv.tail(5))"
      ],
      "metadata": {
        "id": "hebZsOq0uL-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speifying columns Final cost and final sale  to round\n",
        "medical_inv['Final_Cost'] = medical_inv['Final_Cost'].map(lambda x : round(x))\n",
        "medical_inv['Final_Sales'] = medical_inv['Final_Sales'].map(lambda x : round(x))"
      ],
      "metadata": {
        "id": "iHO0yqq8Trcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "Y_aJrgVHS6aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# droping Irrelavent columns\n",
        "medical_inv.drop(['Patient_ID','ReturnQuantity'], axis = True, inplace = True)"
      ],
      "metadata": {
        "id": "cFoHR8_8zyjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_inv.head(10)"
      ],
      "metadata": {
        "id": "8RbTRFDTUCv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descriptive Analytics**"
      ],
      "metadata": {
        "id": "WEwUzxvGUUPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round(medical_inv.describe())"
      ],
      "metadata": {
        "id": "LZAxCRXzUY43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segregate Numeric and Non numeric columns\n"
      ],
      "metadata": {
        "id": "9eG7_M8L1AeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical Features\n",
        "numeric_features = medical_inv.select_dtypes(exclude = ['object','datetime64']).columns\n",
        "numeric_features = numeric_features.drop('Week')\n",
        "display(numeric_features)\n",
        "\n",
        "\n",
        "# Categorical Features\n",
        "categorical_features = medical_inv.select_dtypes(include = ['object']).columns\n",
        "display(categorical_features)"
      ],
      "metadata": {
        "id": "weMuuzNZ09Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Moment Decision - Measure Of Central Tendency"
      ],
      "metadata": {
        "id": "dfmXuK2DU7l-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that \"MULTIPLE ELECTROLYTES 500ML IVF\"\t is the top performing drug"
      ],
      "metadata": {
        "id": "RIFMvsMStYA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean\n",
        "medical_inv[numeric_features].mean()"
      ],
      "metadata": {
        "id": "lk4oqVv8U4AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Median\n",
        "medical_inv[numeric_features].median()"
      ],
      "metadata": {
        "id": "9aPeaZ2aVMh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mode\n",
        "medical_inv.mode()"
      ],
      "metadata": {
        "id": "O9M9A0kfVWha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Moment Bussiness Decision - Measure of Dispersion"
      ],
      "metadata": {
        "id": "YdAXDX5gVjFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variance\n",
        "medical_inv[numeric_features].var()"
      ],
      "metadata": {
        "id": "QfCtkJQoViiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Deviation\n",
        "medical_inv[numeric_features].std()"
      ],
      "metadata": {
        "id": "Z3TxsDmeVxhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third Moment Business Decision - Skewness"
      ],
      "metadata": {
        "id": "J_eq7-5LWHwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skewness\n",
        "medical_inv[numeric_features].skew()"
      ],
      "metadata": {
        "id": "1tsUmD2cWPJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forth Moment Business Decision - Kurtosis"
      ],
      "metadata": {
        "id": "WH7mzfB2WcNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kurtosis\n",
        "medical_inv[numeric_features].kurt()"
      ],
      "metadata": {
        "id": "Nua_ONH7Wlly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "4LELmT4eWwEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Quantity Distribustion"
      ],
      "metadata": {
        "id": "GgJnkPfAZdtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colors to cycle through\n",
        "colors = ['blue', 'red', 'green', 'orange']\n",
        "\n",
        "\n",
        "def EDA(column, colors=colors):\n",
        "    # Get the maximum value of the column\n",
        "    max_value = medical_inv[column].max()\n",
        "\n",
        "    # Randomly select a color from the list\n",
        "    color = np.random.choice(colors)\n",
        "\n",
        "    # Create the histogram\n",
        "    plt.hist(medical_inv[column], color=color, bins=20, alpha=0.7)\n",
        "\n",
        "    # Set the title and labels\n",
        "    plt.title(f'Data Distribution of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Set the x-axis limit\n",
        "    plt.xlim(0, max_value)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WZHlrmT-vstD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(numeric_features)\n",
        "\n",
        "for column in columns:\n",
        "  EDA(column)\n"
      ],
      "metadata": {
        "id": "pdIL57A9wQMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.probplot(medical_inv.Quantity, dist = 'norm', plot = pylab)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S80YB5q-ZgnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Transformation"
      ],
      "metadata": {
        "id": "Y5wMuw2wawjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming the data to a normal distribution\n",
        "stats.probplot(np.log(medical_inv.Quantity), dist = 'norm', plot = pylab)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F_T8mm9CasMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Barplot Quantity of Drug sold by Month\n"
      ],
      "metadata": {
        "id": "-Qd5hbbebUBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data = medical_inv, x = 'Months', y = 'Quantity', palette='muted')\n",
        "plt.title('Quantity of Drugs sold by month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "34GCpZCebTB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Eu3lSD_1k7R2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top Performing drugs**"
      ],
      "metadata": {
        "id": "L9y_94S8m-mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_perform_quantity = medical_inv.groupby(['DrugName','SubCat','SubCat1'], as_index = False)['Quantity'].sum()\n",
        "top_perform_quantity.sort_values(by = 'Quantity',ascending= False,inplace = True)\n",
        "display(top_perform_quantity.head(20))"
      ],
      "metadata": {
        "id": "HjHOvsTfm91j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MWD3hVh5lAGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Based on Quantity\n",
        "top_drugs = medical_inv.groupby(['DrugName'], as_index = False)['Quantity'].sum()\n",
        "top_drugs.sort_values(by = 'Quantity',ascending= False,inplace = True)\n",
        "\n",
        "top_num_drugs = top_drugs.head(50)\n",
        "display(top_num_drugs)"
      ],
      "metadata": {
        "id": "mFgkybwDym5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly = pd.DataFrame(medical_inv.groupby('Months')['Quantity'].sum())\n",
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "\n",
        "# Map month names to numeric values and sort the DataFrame\n",
        "monthly['MonthNum'] = monthly.index.map(dict_month)\n",
        "monthly = monthly.sort_values('MonthNum')\n",
        "monthly.drop(['MonthNum'], axis=1, inplace=True)\n",
        "\n",
        "# Display the result\n",
        "display(monthly)"
      ],
      "metadata": {
        "id": "upmX4tqd-hix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Monthly Quantity\n",
        "Monthly_data = medical_inv.groupby(['DrugName', 'Months'])['Quantity'].sum().reset_index()\n",
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "# Map month names to numeric values and add a new column 'MonthNum'\n",
        "Monthly_data['MonthNum'] = Monthly_data['Months'].map(dict_month)\n",
        "# Sort the DataFrame by 'MonthNum'\n",
        "Monthly_data = Monthly_data.sort_values(by='MonthNum')\n",
        "# Drop the 'Months' column if it's no longer needed\n",
        "Monthly_data.drop(['MonthNum'], axis=1, inplace=True)\n",
        "# Display the result\n",
        "display(Monthly_data)"
      ],
      "metadata": {
        "id": "KL8hGHwCKnjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filtered Data**"
      ],
      "metadata": {
        "id": "s7mHRHIKLJj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the original dataset to include only the top 20 drugs\n",
        "top_drug_names = top_num_drugs['DrugName'].tolist()\n",
        "filtered_data = Monthly_data[Monthly_data['DrugName'].isin(top_drug_names)]\n",
        "# Display the first few rows of the filtered dataset\n",
        "filtered_data.to_csv('Medical_inv_Data.csv')\n",
        "filtered_data"
      ],
      "metadata": {
        "id": "GBTXu4BN0p7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "\n",
        "# Pivot the DataFrame Based on DrugName\n",
        "pivoted_table = filtered_data.pivot_table(index='Months', columns='DrugName', values='Quantity', aggfunc='sum')\n",
        "\n",
        "# Fill NaN values with 0\n",
        "pivoted_table = pivoted_table.fillna(0)\n",
        "\n",
        "# Map month names to numeric values and sort the DataFrame\n",
        "pivoted_table['MonthNum'] = pivoted_table.index.map(dict_month)\n",
        "pivoted_table = pivoted_table.sort_values('MonthNum')\n",
        "pivoted_table.drop(['MonthNum'], axis=1, inplace=True)\n",
        "\n",
        "# Display the result\n",
        "pivoted_table.head(52)"
      ],
      "metadata": {
        "id": "6rZtvTR0Yw6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ploting For Each Column\n",
        "for column in pivoted_table.columns:\n",
        "  plt.figure(figsize = (15,5))\n",
        "  plt.plot(pivoted_table.index, pivoted_table[column], color = 'orange', marker = '*', linestyle = '-', label = column)\n",
        "  plt.title(f'Time Series of {column}')\n",
        "  plt.xlabel('Month of the Year')\n",
        "  plt.xticks(range(len(pivoted_table.index)), pivoted_table.index, rotation=45)\n",
        "  plt.ylabel(column)\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pHAvnha9GRne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering**\n"
      ],
      "metadata": {
        "id": "QKXFj3a7_d2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose the table to have drugs as rows and weeks as columns\n",
        "pivoted_table_T = pivoted_table.T\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MaxAbsScaler()\n",
        "normalized_data = scaler.fit_transform(pivoted_table_T)\n",
        "\n",
        "# Choose the number of clusters (adjust as needed)\n",
        "n_clusters = 3\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "drug_clusters = kmeans.fit_predict(normalized_data)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pivoted_table_T['Cluster'] = drug_clusters\n",
        "\n",
        "# Analyze the clusters\n",
        "cluster_summary = pivoted_table_T.groupby('Cluster').mean()\n",
        "display(cluster_summary)\n",
        "\n",
        "# Compute the silhouette score\n",
        "silhouette_avg = silhouette_score(normalized_data, drug_clusters)\n",
        "display(f'Silhouette Score: {silhouette_avg:.2f}')\n",
        "\n",
        "\n",
        "# Determine the optimal number of clusters using the elbow method\n",
        "TWSS = []\n",
        "k_range = list(range(1, 12))\n",
        "for k in k_range:\n",
        "  kmeans = KMeans(n_clusters = k)\n",
        "  kmeans.fit(normalized_data)\n",
        "  TWSS.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, TWSS, 'ro-')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Sum of squared distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()\n",
        "\n",
        "from kneed import KneeLocator\n",
        "kl = KneeLocator(k_range, TWSS, curve = 'convex', direction = 'decreasing', interp_method = \"interp1d\" )\n",
        "kl.elbow\n",
        "plt.plot(k_range, TWSS)\n",
        "plt.xticks(k_range)\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.axvline(x = kl.elbow, color = 'r',label = 'axvline', ls = '--')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Visualization for clustering using PCA\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(normalized_data)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=drug_clusters, cmap='viridis')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.title('PCA of Drug Clusters')\n",
        "plt.tight_layout()\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Compute the silhouette score\n",
        "silhouette_avg = silhouette_score(normalized_data, drug_clusters)\n",
        "print(f'Silhouette Score: {silhouette_avg:.2f}')\n"
      ],
      "metadata": {
        "id": "2bmgcAPTzAv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Kmeans Time Series Clustering**\n",
        "# Calculate features\n",
        "features = pivoted_table_T.apply([np.mean, np.std, np.max, np.min], axis=1)\n",
        "features['trend'] = pivoted_table_T.apply(lambda x: np.polyfit(range(len(x)), x, 1)[0], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Reshape the data for TimeSeriesKMeans (tslearn requires a specific shape)\n",
        "features_reshaped = features_scaled.reshape((features_scaled.shape[0], features_scaled.shape[1], 1))\n",
        "\n",
        "# Initialize and fit the TimeSeriesKMeans model with the optimal number of clusters\n",
        "optimal_clusters = 3 # Replace this with the actual optimal k from the elbow curve\n",
        "model = TimeSeriesKMeans(n_clusters=optimal_clusters, metric=\"dtw\", random_state=42)\n",
        "clusters = model.fit_predict(features_reshaped)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pivoted_table_T['Cluster'] = clusters\n",
        "\n",
        "# Calculate the Silhouette Score\n",
        "sil_score = silhouette_score(features_scaled, clusters)\n",
        "display(f'Silhouette Score for {optimal_clusters} clusters: {sil_score}')# Plot the Silhouette Score for different k values\n",
        "sil_scores = []\n",
        "for k in k_range[1:]:\n",
        "    model = TimeSeriesKMeans(n_clusters=k, metric=\"dtw\", random_state=42)\n",
        "    labels = model.fit_predict(features_reshaped)\n",
        "    sil_score = silhouette_score(features_scaled, labels)\n",
        "    sil_scores.append(sil_score)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range[1:], sil_scores, marker='o', color = 'g')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "omWFrsMDAUy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cluster Evaluation"
      ],
      "metadata": {
        "id": "PFD6r84s829F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "round(metrics.silhouette_score(features_scaled, clusters),2)"
      ],
      "metadata": {
        "id": "CeGIm5P381Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sorting the data By Clusters\n",
        "# Sorting the data by 'Cluster' column\n",
        "sorted_data = pivoted_table_T.sort_values(by='Cluster')\n",
        "\n",
        "clusters = sorted_data\n",
        "\n",
        "clusters = clusters.T"
      ],
      "metadata": {
        "id": "ab26wx24lRo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot sales data for each drug within a cluster\n",
        "def plot_drug_sales(cluster_data, cluster_number):\n",
        "    drugs = cluster_data.columns\n",
        "    for drug in drugs:\n",
        "        drug_data = cluster_data[drug].dropna()\n",
        "        if not drug_data.empty:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(drug_data.index, drug_data.values, marker='o')\n",
        "            plt.xlabel('Date')\n",
        "            plt.ylabel('Quantity Sold')\n",
        "            plt.title(f'{drug} Sales in Cluster {cluster_number}')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "# Create separate DataFrames for each cluster\n",
        "cluster_0 = sorted_data[sorted_data['Cluster'] == 0].drop(columns='Cluster').T\n",
        "cluster_1 = sorted_data[sorted_data['Cluster'] == 1].drop(columns='Cluster').T\n",
        "cluster_2 = sorted_data[sorted_data['Cluster'] == 2].drop(columns='Cluster').T"
      ],
      "metadata": {
        "id": "17UQM46nGGnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Drugs in Each Cluster\n",
        "# Create a mapping between drug names and clusters\n",
        "drug_cluster_mapping = {}\n",
        "\n",
        "for cluster_num, cluster_data in zip(range(n_clusters), [cluster_0, cluster_1, cluster_2]):\n",
        "    for drug_name in cluster_data.columns:\n",
        "        drug_cluster_mapping[drug_name] = cluster_num\n",
        "\n",
        "# Add the 'Cluster' column to the filtered_data DataFrame\n",
        "filtered_data['Cluster'] = filtered_data['DrugName'].map(drug_cluster_mapping)\n",
        "grouped_data = filtered_data.groupby('Cluster')\n",
        "\n",
        "for cluster, group_data in grouped_data:\n",
        "    unique_drug_names = group_data['DrugName'].unique()\n",
        "    unique_drug_count = len(unique_drug_names)\n",
        "    print(f\"Cluster {cluster}:,\\n\")\n",
        "    print(f\"Unique Drug Names ({unique_drug_count} drugs):,\\n\")\n",
        "    print(unique_drug_names)\n",
        "    print()"
      ],
      "metadata": {
        "id": "UqPFKDCPggDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualaization for Each Cluster Sales Over Monthly\n",
        "# Function to plot all drugs' sales data within a cluster\n",
        "def plot_cluster_sales(cluster_data, cluster_number):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for drug in cluster_data.columns:\n",
        "        drug_data = cluster_data[drug].dropna()\n",
        "        if not drug_data.empty:\n",
        "            plt.plot(drug_data.index, drug_data.values, marker='o', label=drug)\n",
        "    plt.xlabel('Week')\n",
        "    plt.ylabel('Quantity Sold')\n",
        "    plt.title(f'Sales in Cluster {cluster_number}')\n",
        "    # Customize x-axis ticks to show labels at even intervals of weeks\n",
        "    num_weeks = len(cluster_data.index)\n",
        "    xticks_loc = np.arange(0, num_weeks, 3)  # Show labels every 2 weeks\n",
        "    xticks_labels = [cluster_data.index[i] for i in xticks_loc]\n",
        "    plt.xticks(xticks_loc, xticks_labels, rotation=45)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Filter and transpose data by cluster\n",
        "for cluster_number in sorted_data['Cluster'].unique():\n",
        "    cluster_data = sorted_data[sorted_data['Cluster'] == cluster_number].drop(columns='Cluster').T\n",
        "    plot_cluster_sales(cluster_data, cluster_number)\n"
      ],
      "metadata": {
        "id": "JUkNlov1HEPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualaization of sales for each drug in each cluster (Optional)"
      ],
      "metadata": {
        "id": "WHOgHEq9JVTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for Cluster 0\n",
        "#plot_drug_sales(cluster_0, 0)"
      ],
      "metadata": {
        "id": "g1WWuaMsGQin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for Cluster 1\n",
        "#plot_drug_sales(cluster_1, 1)"
      ],
      "metadata": {
        "id": "2649qAjdGSih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for Cluster 2\n",
        "#plot_drug_sales(cluster_2, 2)\n"
      ],
      "metadata": {
        "id": "vvRtiufkGUBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building**"
      ],
      "metadata": {
        "id": "wG8F_lYEiJ6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title SARIMA Model ON Clusters\n",
        "# Forecast for each cluster\n",
        "for cluster in range(optimal_clusters):\n",
        "    cluster_data = filtered_data[filtered_data['Cluster'] == cluster]\n",
        "\n",
        "    # Find the most frequently sold drug in the cluster\n",
        "    top_drug = cluster_data.groupby('DrugName')['Quantity'].sum().nlargest(1).reset_index()['DrugName'].values[0]\n",
        "    drug_data = cluster_data[cluster_data['DrugName'] == top_drug]\n",
        "\n",
        "    # Set 'Monthly_Period' as the index\n",
        "    drug_data.set_index('Months', inplace=True)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_size = int(len(drug_data) * 0.8)\n",
        "    train_data, test_data = drug_data.iloc[:train_size], drug_data.iloc[train_size:]\n",
        "\n",
        "    # Find the best SARIMA parameters\n",
        "    best_mape = float(\"inf\")\n",
        "    best_pdq = None\n",
        "    best_seasonal_pdq = None\n",
        "\n",
        "    p = d = q = range(0, 3)\n",
        "    pdq = list(itertools.product(p, d, q))\n",
        "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "    for param in pdq:\n",
        "        for param_seasonal in seasonal_pdq:\n",
        "            try:\n",
        "                mod = SARIMAX(train_data['Quantity'],\n",
        "                              order=param,\n",
        "                              seasonal_order=param_seasonal,\n",
        "                              enforce_stationarity=False,\n",
        "                              enforce_invertibility=False)\n",
        "                results = mod.fit(disp=False)\n",
        "                forecast = results.get_forecast(steps=len(test_data))\n",
        "                predicted_mean = forecast.predicted_mean\n",
        "                mape = mean_absolute_percentage_error(test_data['Quantity'], predicted_mean)\n",
        "                if mape < best_mape:\n",
        "                    best_mape = mape\n",
        "                    best_pdq = param\n",
        "                    best_seasonal_pdq = param_seasonal\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    print(f'Best SARIMA parameters for Cluster {cluster}: {best_pdq} x {best_seasonal_pdq}')\n",
        "    print(f'Best MAPE for Cluster {cluster}: {best_mape}')\n",
        "\n",
        "    # Fit the best SARIMA model\n",
        "    best_sarima_model = SARIMAX(train_data['Quantity'],\n",
        "                                order=best_pdq,\n",
        "                                seasonal_order=best_seasonal_pdq,\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "    best_sarima_fit = best_sarima_model.fit(disp=False)\n",
        "\n",
        "    # Forecast the future sales\n",
        "    n_forecast = len(test_data)\n",
        "    forecast = best_sarima_fit.get_forecast(steps=n_forecast)\n",
        "    forecast_index = test_data.index\n",
        "\n",
        "    # Plot the forecast\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_data.index, train_data['Quantity'], label='Train')\n",
        "    plt.plot(test_data.index, test_data['Quantity'], label='Test')\n",
        "    plt.plot(forecast_index, forecast.predicted_mean, label='Forecast')\n",
        "    plt.fill_between(forecast_index, forecast.conf_int()['lower Quantity'], forecast.conf_int()['upper Quantity'], color='k', alpha=0.1)\n",
        "    plt.xlabel('Week')\n",
        "    plt.ylabel('Quantity Sold')\n",
        "    plt.title(f'SARIMA Forecast for Cluster {cluster} ({top_drug})')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yw6oVz5jiJhJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Forescasting Model for Top 20 individual Drug\n",
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "\n",
        "# Pivot the DataFrame Based on DrugName\n",
        "pivoted_table = filtered_data.pivot_table(index='Months', columns='DrugName', values='Quantity', aggfunc='sum')\n",
        "\n",
        "# Fill NaN values with 0\n",
        "pivoted_table = pivoted_table.fillna(0)\n",
        "\n",
        "# Sum the total quantity for each drug\n",
        "total_quantity_per_drug = pivoted_table.sum()\n",
        "\n",
        "# Select the top 20 drugs by total quantity\n",
        "top_20_drugs = total_quantity_per_drug.nlargest(20).index\n",
        "\n",
        "# Filter the pivoted table to include only the top 20 drugs\n",
        "pivoted_table_top_20 = pivoted_table[top_20_drugs]\n",
        "\n",
        "# Map month names to numeric values and sort the DataFrame\n",
        "pivoted_table_top_20['MonthNum'] = pivoted_table_top_20.index.map(dict_month)\n",
        "pivoted_table_top_20 = pivoted_table_top_20.sort_values('MonthNum')\n",
        "pivoted_table_top_20.drop(['MonthNum'], axis=1, inplace=True)\n",
        "\n",
        "# Forecast for each drug\n",
        "for drug in pivoted_table_top_20.columns:\n",
        "    drug_data = pivoted_table_top_20[[drug]].copy()\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_size = int(len(drug_data) * 0.8)\n",
        "    train_data, test_data = drug_data.iloc[:train_size], drug_data.iloc[train_size:]\n",
        "\n",
        "    # Find the best SARIMA parameters\n",
        "    best_mape = float(\"inf\")\n",
        "    best_pdq = None\n",
        "    best_seasonal_pdq = None\n",
        "\n",
        "    p = d = q = range(0, 3)\n",
        "    pdq = list(itertools.product(p, d, q))\n",
        "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "    for param in pdq:\n",
        "        for param_seasonal in seasonal_pdq:\n",
        "            try:\n",
        "                mod = SARIMAX(train_data[drug],\n",
        "                              order=param,\n",
        "                              seasonal_order=param_seasonal,\n",
        "                              enforce_stationarity=True,\n",
        "                              enforce_invertibility=False)\n",
        "                results = mod.fit(disp=False)\n",
        "                forecast = results.get_forecast(steps=len(test_data))\n",
        "                predicted_mean = forecast.predicted_mean\n",
        "                mape = mean_absolute_percentage_error(test_data[drug], predicted_mean)\n",
        "                if mape < best_mape:\n",
        "                    best_mape = mape\n",
        "                    best_pdq = param\n",
        "                    best_seasonal_pdq = param_seasonal\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    print(f'Best SARIMA parameters for {drug}: {best_pdq} x {best_seasonal_pdq}')\n",
        "    print(f'Best MAPE for {drug}: {best_mape}')\n",
        "\n",
        "    # Fit the best SARIMA model\n",
        "    best_sarima_model = SARIMAX(train_data[drug],\n",
        "                                order=best_pdq,\n",
        "                                seasonal_order=best_seasonal_pdq,\n",
        "                                enforce_stationarity=True,\n",
        "                                enforce_invertibility=False)\n",
        "    best_sarima_fit = best_sarima_model.fit(disp=False)\n",
        "\n",
        "    # Forecast the future sales\n",
        "    n_forecast = len(test_data)\n",
        "    forecast = best_sarima_fit.get_forecast(steps=n_forecast)\n",
        "    forecast_index = test_data.index\n",
        "\n",
        "    # Plot the forecast\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_data.index, train_data[drug], label='Train')\n",
        "    plt.plot(test_data.index, test_data[drug], label='Test')\n",
        "    plt.plot(forecast_index, forecast.predicted_mean, label='Forecast')\n",
        "    plt.fill_between(forecast_index, forecast.conf_int()['lower ' + drug], forecast.conf_int()['upper ' + drug], color='k', alpha=0.1)\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Quantity Sold')\n",
        "    plt.title(f'SARIMA Forecast for {drug}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "THscSDaD7vYW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Forcasting for next four months of 2023\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "\n",
        "# Pivot the DataFrame Based on DrugName\n",
        "pivoted_table = filtered_data.pivot_table(index='Months', columns='DrugName', values='Quantity', aggfunc='sum')\n",
        "\n",
        "# Fill NaN values with 0\n",
        "pivoted_table = pivoted_table.fillna(0)\n",
        "\n",
        "# Sum the total quantity for each drug\n",
        "total_quantity_per_drug = pivoted_table.sum()\n",
        "\n",
        "# Select the top 20 drugs by total quantity\n",
        "top_20_drugs = total_quantity_per_drug.nlargest(20).index\n",
        "\n",
        "# Filter the pivoted table to include only the top 20 drugs\n",
        "pivoted_table_top_20 = pivoted_table[top_20_drugs]\n",
        "\n",
        "# Map month names to numeric values and sort the DataFrame\n",
        "pivoted_table_top_20['MonthNum'] = pivoted_table_top_20.index.map(dict_month)\n",
        "pivoted_table_top_20 = pivoted_table_top_20.sort_values('MonthNum')\n",
        "pivoted_table_top_20.drop(['MonthNum'], axis=1, inplace=True)\n",
        "\n",
        "# Predefined SARIMA parameters\n",
        "sarima_params_dict = {\n",
        "    0: {'pdq': (1, 1, 0), 'seasonal_pdq': (0, 0, 0, 12)},\n",
        "    1: {'pdq': (2, 1, 0), 'seasonal_pdq': (0, 0, 0, 12)},\n",
        "    2: {'pdq': (0, 1, 0), 'seasonal_pdq': (0, 0, 0, 12)},\n",
        "    3: {'pdq': (1, 1, 0), 'seasonal_pdq': (0, 0, 0, 12)},\n",
        "}\n",
        "\n",
        "# Forecast for each drug\n",
        "for i, drug in enumerate(pivoted_table_top_20.columns):\n",
        "    drug_data = pivoted_table_top_20[[drug]].copy()\n",
        "\n",
        "    # Check stationarity and apply differencing if necessary\n",
        "    def check_stationarity(timeseries):\n",
        "        from statsmodels.tsa.stattools import adfuller\n",
        "        result = adfuller(timeseries)\n",
        "        return result[1]  # p-value\n",
        "\n",
        "    p_value = check_stationarity(drug_data[drug])\n",
        "    if p_value > 0.05:\n",
        "        drug_data[drug] = drug_data[drug].diff().dropna()\n",
        "\n",
        "    # Get the predefined SARIMA parameters\n",
        "    params = sarima_params_dict[i % len(sarima_params_dict)]\n",
        "    pdq = params['pdq']\n",
        "    seasonal_pdq = params['seasonal_pdq']\n",
        "\n",
        "    # Fit the SARIMA model with predefined parameters\n",
        "    best_sarima_model = SARIMAX(drug_data[drug],\n",
        "                                order=pdq,\n",
        "                                seasonal_order=seasonal_pdq,\n",
        "                                enforce_stationarity=True,\n",
        "                                enforce_invertibility=False)\n",
        "    best_sarima_fit = best_sarima_model.fit(disp=False)\n",
        "\n",
        "    # Forecast the future sales for Jan and Feb 2023\n",
        "    n_forecast = 4  # Forecast for two additional months\n",
        "    forecast = best_sarima_fit.get_forecast(steps=n_forecast)\n",
        "\n",
        "    # Get the last date in the original data\n",
        "    last_date = pd.to_datetime(drug_data.index[-1], format='%b')\n",
        "\n",
        "    # Create forecast index for the next two months\n",
        "    forecast_index = [last_date + pd.DateOffset(months=i) for i in range(1, n_forecast + 1)]\n",
        "\n",
        "    # Convert forecast_index to month names\n",
        "    forecast_index = [date.strftime('%b') for date in forecast_index]\n",
        "\n",
        "    # Plot the forecast\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(drug_data.index, drug_data[drug], label='Actual')\n",
        "    plt.plot(forecast_index, forecast.predicted_mean, label='Forecast', marker='o')\n",
        "    plt.fill_between(forecast_index, forecast.conf_int().iloc[:, 0], forecast.conf_int().iloc[:, 1], color='k', alpha=0.1)\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Quantity Sold')\n",
        "    plt.title(f'SARIMA Forecast for {drug} (Including Jan and Feb 2023)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "import joblib, pickle\n",
        "\n",
        "# Save essential components\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "with open('kmeans_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "with open('sarima_params_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(sarima_params_dict, f)\n",
        "\n",
        "with open('filtered_data.pkl', 'wb') as f:\n",
        "    pickle.dump(filtered_data, f)"
      ],
      "metadata": {
        "id": "XQg2eh3NV85Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, pickle\n",
        "\n",
        "# Save essential components\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "with open('kmeans_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "with open('sarima_params_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(sarima_params_dict, f)\n",
        "\n",
        "with open('filtered_data.pkl', 'wb') as f:\n",
        "    pickle.dump(filtered_data, f)"
      ],
      "metadata": {
        "id": "ilR7pYkNJ_0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/Users/pavankumar/Projects/Medical Inventory Management')\n",
        "os.getcwd  ()"
      ],
      "metadata": {
        "id": "2N2Z_Izf7M7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model"
      ],
      "metadata": {
        "id": "0tLlX1fGlL0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Assuming filtered_data DataFrame is defined\n",
        "# List of unique drug names\n",
        "top_drug_names = filtered_data['DrugName'].unique()\n",
        "\n",
        "# Convert DrugName to categorical and encode it\n",
        "filtered_data['DrugName'] = filtered_data['DrugName'].astype('category')\n",
        "filtered_data['DrugName_cat'] = filtered_data['DrugName'].cat.codes\n",
        "\n",
        "# Scale the Quantity feature\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "filtered_data['Quantity_scaled'] = scaler.fit_transform(filtered_data['Quantity'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare the data for LSTM\n",
        "def create_dataset(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Define the number of time steps\n",
        "TIME_STEPS = 10\n",
        "\n",
        "# Create the LSTM input sequences and target values\n",
        "X, y = create_dataset(filtered_data[['Quantity_scaled', 'Cluster', 'DrugName_cat']], filtered_data['Quantity_scaled'], TIME_STEPS)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split_index = int(0.8 * len(X))\n",
        "X_train, X_test, y_train, y_test = X[:split_index], X[split_index:], y[:split_index], y[split_index:]\n",
        "\n",
        "# Define MAPE custom metric\n",
        "def mape_metric(y_true, y_pred):\n",
        "    epsilon = 1e-10  # small value to avoid division by zero\n",
        "    return K.mean(K.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "# Define the custom MAPE metric for Keras\n",
        "def mape_metric(y_true, y_pred):\n",
        "    epsilon = 1e-10  # small value to avoid division by zero\n",
        "    mask = K.greater(y_true, epsilon)  # create a mask for non-zero true values\n",
        "    masked_true = K.cast(mask, K.floatx()) * y_true  # apply mask to true values\n",
        "    masked_pred = K.cast(mask, K.floatx()) * y_pred  # apply mask to predicted values\n",
        "    return K.mean(K.abs((masked_true - masked_pred) / (masked_true + epsilon))) * 100\n",
        "\n",
        "# Define the LSTM model architecture\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[mape_metric])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "mse, mape = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Mean Absolute Percentage Error: {mape}')\n"
      ],
      "metadata": {
        "id": "uLO5jELUq99g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment Part Essentials**"
      ],
      "metadata": {
        "id": "qdcF0i5TBoyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/Users/pavankumar/Projects/Medical Inventory Management/Datasets/Medical Inventory Optimaization Dataset.xlsx')\n"
      ],
      "metadata": {
        "id": "CpMMl6EjDXRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(inplace = True)\n",
        "data.reset_index(drop = True, inplace = True)\n",
        "group_cols = ['Typeofsales','Specialisation','Dept']\n",
        "\n",
        "for col in ['Formulation', 'DrugName', 'SubCat', 'SubCat1']:\n",
        "    data[col] = data.groupby(group_cols)[col].transform(lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x)\n",
        "\n",
        "data.reset_index(drop = True, inplace = True)\n",
        "data.dropna(inplace = True)\n",
        "data['Dateofbill'] = pd.to_datetime(data['Dateofbill'])\n",
        "data = data.sort_values(by = 'Dateofbill', ascending = True)\n",
        "data['Months'] = data['Dateofbill'].dt.strftime(\"%b\")\n",
        "\n",
        "Monthly_data = data.groupby(['DrugName', 'Months'])['Quantity'].sum().reset_index()\n",
        "# Create Dictionary to map month names into numeric values\n",
        "dict_month = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "              'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
        "# Map month names to numeric values and add a new column 'MonthNum'\n",
        "Monthly_data['MonthNum'] = Monthly_data['Months'].map(dict_month)\n",
        "# Sort the DataFrame by 'MonthNum'\n",
        "Monthly_data = Monthly_data.sort_values(by='MonthNum')\n",
        "# Drop the 'Months' column if it's no longer needed\n",
        "Monthly_data.drop(['MonthNum'], axis=1, inplace=True)\n",
        "# Display the result\n",
        "display(Monthly_data)\n",
        "\n",
        "top_drugs = data.groupby(['DrugName'], as_index = False)['Quantity'].sum()\n",
        "top_drugs.sort_values(by = 'Quantity',ascending= False,inplace = True)\n",
        "\n",
        "top_num_drugs = top_drugs.head(50)\n",
        "display(top_num_drugs)\n",
        "\n",
        "#Filter the original dataset to include only the top 20 drugs\n",
        "top_drug_names = top_num_drugs['DrugName'].tolist()\n",
        "filtered_data = Monthly_data[Monthly_data['DrugName'].isin(top_drug_names)]\n",
        "filtered_data"
      ],
      "metadata": {
        "id": "7-ANrQBdBmgJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}